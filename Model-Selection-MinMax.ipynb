{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from feature_engineering import *\n",
    "from config import *\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import CreateDataset\n",
    "\n",
    "sr = CreateDataset.sr\n",
    "fs = CreateDataset.fs\n",
    "hs = CreateDataset.hs\n",
    "mfcc_dim = CreateDataset.mfcc_dim\n",
    "cs = CreateDataset.cs\n",
    "ms = CreateDataset.ms\n",
    "ts = CreateDataset.ts\n",
    "data_path = CreateDataset.data_path\n",
    "\n",
    "def extract_feature(samples):\n",
    "    result = []\n",
    "    features = []\n",
    "\n",
    "    # Timbre features\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=samples, sr=sr, n_fft=fs, hop_length=hs)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=samples, sr=sr, n_fft=fs, hop_length=hs)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=samples, sr=sr, n_fft=fs, hop_length=hs)\n",
    "    spectral_rollof = librosa.feature.spectral_rolloff(y=samples, sr=sr, n_fft=fs, hop_length=hs)\n",
    "    spectral_flux = librosa.onset.onset_strength(y=samples, sr=sr, center=True)\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(y=samples, frame_length=fs, hop_length=hs)\n",
    "    mfcc = librosa.feature.mfcc(y=samples, sr=sr, n_fft=fs, hop_length=hs)\n",
    "    mel_scale = librosa.feature.melspectrogram(y=samples, n_fft=fs, hop_length=hs, sr=sr)\n",
    "    mel_scale = librosa.power_to_db(mel_scale)\n",
    "    \n",
    "    \n",
    "    # 리듬 feature\n",
    "    tempo = librosa.beat.tempo(y=samples, sr=sr, hop_length=hs)\n",
    "    \n",
    "    # pitch feature\n",
    "    chroma = librosa.feature.chroma_stft(y=samples, sr=sr, hop_length=hs, n_fft=fs, n_chroma=cs)\n",
    "#     tonal_centroid = librosa.feature.tonnetz(y=samples, sr=sr)\n",
    "\n",
    "    features.append(spectral_contrast)\n",
    "    features.append(spectral_bandwidth)\n",
    "    features.append(spectral_centroid)\n",
    "    features.append(spectral_rollof)\n",
    "    features.append(zero_crossing)\n",
    "    features.append(spectral_flux)\n",
    "    \n",
    "    features.append(tempo)\n",
    "\n",
    "    for feature in features:\n",
    "        result.append(np.mean(feature))\n",
    "        result.append(np.std(feature))\n",
    "\n",
    "    for i in range(0, mfcc_dim):\n",
    "        result.append(np.mean(mfcc[i,:]))\n",
    "        result.append(np.std(mfcc[i, :]))\n",
    "\n",
    "    for i in range(0, ms):\n",
    "        result.append(np.mean(mel_scale[i, :]))\n",
    "        result.append(np.std(mel_scale[i, :]))\n",
    "        \n",
    "    for i in range(0, cs):\n",
    "        result.append(np.mean(chroma[i, :]))\n",
    "        result.append(np.std(chroma[i, :]))\n",
    "        \n",
    "#     for i in range(0, ts):\n",
    "#         result.append(np.mean(tonal_centroid[i, :]))\n",
    "#         result.append(np.std(tonal_centroid[i, :]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampels(data_set='train'):\n",
    "    audios = []\n",
    "    labels = []\n",
    "    path_of_audios = librosa.util.find_files(data_path + data_set)\n",
    "    for audio in path_of_audios:\n",
    "        labels.append(audio.split('train/')[1].split('_')[0])\n",
    "        y, sr = librosa.load(audio, sr=22050, duration=4.0)\n",
    "        audios.append(y)\n",
    "    audios_numpy = np.array(audios)\n",
    "    return audios_numpy, labels\n",
    "\n",
    "is_created = False\n",
    "audios_numpy, labels = get_sampels(data_set='train')\n",
    "for samples in audios_numpy:\n",
    "    row = extract_feature(samples)\n",
    "    if not is_created:\n",
    "        dataset_numpy = np.array(row)\n",
    "        is_created = True\n",
    "    elif is_created:\n",
    "        dataset_numpy = np.vstack((dataset_numpy, row))\n",
    "\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "dataset_numpy = scaler.fit_transform(dataset_numpy)\n",
    "\n",
    "data_set = pd.DataFrame(dataset_numpy)\n",
    "data_set[\"instruments\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 85\n"
     ]
    }
   ],
   "source": [
    "data_set = np.array(data_set)\n",
    "# Cacluate Shape\n",
    "row, col = data_set.shape\n",
    "print(row,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_set[:, :col-1]\n",
    "y = data_set[:, col-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = librosa.util.find_files(\"./dataset/test\")\n",
    "\n",
    "test_Y = []\n",
    "samples = []\n",
    "for p in PATH:\n",
    "    test_Y.append(p.split('test/')[1].split('_')[0])\n",
    "    sample, sr = librosa.load(p, sr=22050, duration=4.0)\n",
    "    samples.append(sample)\n",
    "\n",
    "data = np.array([extract_feature(sample) for sample in samples])\n",
    "\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "test_X = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 84)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier, LogisticRegression\n",
    "from sklearn import ensemble, naive_bayes, svm, tree, discriminant_analysis, neighbors, feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [    \n",
    "        # Generalized Linear Models\n",
    "        LogisticRegressionCV(),\n",
    "        # SVM\n",
    "        svm.SVC(probability = True),\n",
    "        svm.LinearSVC(),\n",
    "        # KNN\n",
    "        neighbors.KNeighborsClassifier(weights='distance'),\n",
    "        # Naive Bayes\n",
    "        naive_bayes.GaussianNB(),\n",
    "        #Trees    \n",
    "        tree.DecisionTreeClassifier(),\n",
    "        ensemble.RandomForestClassifier()\n",
    "    ]\n",
    "\n",
    "cv_split = ShuffleSplit(n_splits = 5, test_size = .8, train_size = .2, random_state = 0)\n",
    "MLA_columns = ['MLA Name','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean','MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    cv_results = cross_validate(alg, x, y, cv=cv_split, return_train_score=True)\n",
    "    \n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Val Accuracy Mean'] = cv_results['test_score'].mean()    \n",
    "    alg.fit(x, y)\n",
    "    test_Y_hat = alg.predict(test_X)\n",
    "    accuracy = np.sum((test_Y_hat == test_Y))/200.0*100.0\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = accuracy\n",
    "    row_index+=1\n",
    "    \n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Time</th>\n",
       "      <th>MLA Val Accuracy Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>86.5</td>\n",
       "      <td>2.59744</td>\n",
       "      <td>0.877083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.798333</td>\n",
       "      <td>84.5</td>\n",
       "      <td>0.0720632</td>\n",
       "      <td>0.630417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0.132678</td>\n",
       "      <td>0.889583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.0472243</td>\n",
       "      <td>0.857083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0151406</td>\n",
       "      <td>0.673333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.95</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0139742</td>\n",
       "      <td>0.824583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0345453</td>\n",
       "      <td>0.779375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MLA Name MLA Train Accuracy Mean MLA Test Accuracy Mean  \\\n",
       "0    LogisticRegressionCV                0.999167                   86.5   \n",
       "1                     SVC                0.798333                   84.5   \n",
       "2               LinearSVC                       1                     83   \n",
       "6  RandomForestClassifier                0.995833                   77.5   \n",
       "3    KNeighborsClassifier                       1                     75   \n",
       "4              GaussianNB                    0.95                     72   \n",
       "5  DecisionTreeClassifier                       1                     67   \n",
       "\n",
       "    MLA Time  MLA Val Accuracy Mean  \n",
       "0    2.59744               0.877083  \n",
       "1  0.0720632               0.630417  \n",
       "2   0.132678               0.889583  \n",
       "6  0.0472243               0.857083  \n",
       "3  0.0151406               0.673333  \n",
       "4  0.0139742               0.824583  \n",
       "5  0.0345453               0.779375  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_score: 1.0 test_score: 0.9104166666666667\n",
      "epoch: 1 train_score: 1.0 test_score: 0.9177083333333333\n",
      "epoch: 2 train_score: 1.0 test_score: 0.8979166666666667\n",
      "epoch: 3 train_score: 1.0 test_score: 0.9\n",
      "epoch: 4 train_score: 1.0 test_score: 0.8895833333333333\n",
      "-----\n",
      "AFTER Tuning Parameters:  {'C': 2.0, 'gamma': 0.02, 'kernel': 'linear'}\n",
      "AFTER Tuning Training w/bin score mean: 100.00\n",
      "AFTER Tuning Test w/bin score mean: 90.31\n",
      "-----\n",
      "SVC(C=2.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.02, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "test accuracy = 91.0 %\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C':[0.5,1.0,2.0, 3.0],  # penalty parameter C of the error term\n",
    "              'kernel':['linear', 'rbf'], # specifies the kernel type to be used in the algorithm  \n",
    "              'gamma':[0.02, 0.08,0.2,1.0] # kernel coefficient for 'rbf'\n",
    "             }\n",
    "\n",
    "# Grid Search\n",
    "tune_model = GridSearchCV(svm.SVC(), param_grid=param_grid, scoring = 'accuracy', cv = cv_split, return_train_score=True)\n",
    "tune_model.fit(x, y)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"epoch:\",i,\"train_score:\",tune_model.cv_results_['split'+str(i)+'_train_score'][tune_model.best_index_],\n",
    "    \"test_score:\",tune_model.cv_results_['split'+str(i)+'_test_score'][tune_model.best_index_])\n",
    "\n",
    "print('-'*5)    \n",
    "\n",
    "print('AFTER Tuning Parameters: ', tune_model.best_params_)\n",
    "print(\"AFTER Tuning Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER Tuning Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print('-'*5)\n",
    "\n",
    "best_log = tune_model.best_estimator_\n",
    "print(best_log)\n",
    "#accuracy on test\n",
    "test_Y_hat = best_log.predict(test_X)\n",
    "accuracy = np.sum((test_Y_hat == test_Y))/200.0*100.0\n",
    "print('test accuracy = ' + str(accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_score: 1.0 test_score: 0.7166666666666667\n",
      "epoch: 1 train_score: 1.0 test_score: 0.6791666666666667\n",
      "epoch: 2 train_score: 1.0 test_score: 0.703125\n",
      "epoch: 3 train_score: 1.0 test_score: 0.709375\n",
      "epoch: 4 train_score: 1.0 test_score: 0.6385416666666667\n",
      "----------\n",
      "AFTER Tuning Parameters:  {'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'}\n",
      "AFTER Tuning Training w/bin score mean: 100.00\n",
      "AFTER Tuning Test w/bin score mean: 68.94\n",
      "----------\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
      "           weights='distance')\n",
      "test accuracy = 74.0 %\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameters Set\n",
    "param_grid = {'n_neighbors':[5,6,7,8,9,10],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'n_jobs':[-1]}\n",
    "\n",
    "tune_model = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid=param_grid, scoring = 'accuracy', cv = cv_split, return_train_score=True)\n",
    "tune_model.fit(x, y)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"epoch:\",i,\"train_score:\",tune_model.cv_results_['split'+str(i)+'_train_score'][tune_model.best_index_],\n",
    "    \"test_score:\",tune_model.cv_results_['split'+str(i)+'_test_score'][tune_model.best_index_])\n",
    "\n",
    "print('-'*10)    \n",
    "\n",
    "print('AFTER Tuning Parameters: ', tune_model.best_params_)\n",
    "print(\"AFTER Tuning Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER Tuning Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print('-'*10)\n",
    "\n",
    "best_log = tune_model.best_estimator_\n",
    "print(best_log)\n",
    "#accuracy on test\n",
    "test_Y_hat = best_log.predict(test_X)\n",
    "accuracy = np.sum((test_Y_hat == test_Y))/200.0*100.0\n",
    "print('test accuracy = ' + str(accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_score: 1.0 test_score: 0.8979166666666667\n",
      "epoch: 1 train_score: 1.0 test_score: 0.8895833333333333\n",
      "epoch: 2 train_score: 1.0 test_score: 0.878125\n",
      "epoch: 3 train_score: 1.0 test_score: 0.8875\n",
      "epoch: 4 train_score: 1.0 test_score: 0.88125\n",
      "-----\n",
      "AFTER Tuning Parameters:  {'C': 100, 'random_state': 42, 'tol': 1e-06}\n",
      "AFTER Tuning Training w/bin score mean: 100.00\n",
      "AFTER Tuning Test w/bin score mean: 88.69\n",
      "-----\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=1e-06,\n",
      "          verbose=0, warm_start=False)\n",
      "test accuracy = 81.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungheondoh/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/seungheondoh/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/seungheondoh/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/seungheondoh/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/seungheondoh/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/seungheondoh/anaconda3/envs/python3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "             'tol': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "             'random_state' : [42]}\n",
    "\n",
    "tune_model = GridSearchCV(LogisticRegression(), param_grid, cv = cv_split, scoring= 'accuracy')\n",
    "tune_model.fit(x, y)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"epoch:\",i,\"train_score:\",tune_model.cv_results_['split'+str(i)+'_train_score'][tune_model.best_index_],\n",
    "    \"test_score:\",tune_model.cv_results_['split'+str(i)+'_test_score'][tune_model.best_index_])\n",
    "\n",
    "print('-'*5)    \n",
    "\n",
    "print('AFTER Tuning Parameters: ', tune_model.best_params_)\n",
    "print(\"AFTER Tuning Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER Tuning Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print('-'*5)\n",
    "\n",
    "\n",
    "#let's see the best estimator\n",
    "best_log = tune_model.best_estimator_\n",
    "print(best_log)\n",
    "#accuracy on test\n",
    "test_Y_hat = best_log.predict(test_X)\n",
    "accuracy = np.sum((test_Y_hat == test_Y))/200.0*100.0\n",
    "print('test accuracy = ' + str(accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_score: 1.0 test_score: 0.7875\n",
      "epoch: 1 train_score: 1.0 test_score: 0.8197916666666667\n",
      "epoch: 2 train_score: 1.0 test_score: 0.8333333333333334\n",
      "epoch: 3 train_score: 1.0 test_score: 0.7864583333333334\n",
      "epoch: 4 train_score: 1.0 test_score: 0.7833333333333333\n",
      "-----\n",
      "AFTER Tuning Parameters:  {'criterion': 'entropy', 'max_depth': 8, 'random_state': 0, 'splitter': 'best'}\n",
      "AFTER Tuning Training w/bin score mean: 100.00\n",
      "AFTER Tuning Test w/bin score mean: 80.21\n",
      "----------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n",
      "test accuracy = 62.5 %\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'criterion': ['gini','entropy'], \n",
    "              'splitter': ['best', 'random'], \n",
    "              'max_depth': [2,4,6,8,10,None], \n",
    "              #'min_samples_split': [2,5,7,10,12], \n",
    "              #'min_samples_leaf': [1,3,5,7, 10], \n",
    "              'random_state': [0] \n",
    "             }\n",
    "tune_model = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'accuracy', cv = cv_split, return_train_score=True)\n",
    "tune_model.fit(x, y)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"epoch:\",i,\"train_score:\",tune_model.cv_results_['split'+str(i)+'_train_score'][tune_model.best_index_],\n",
    "    \"test_score:\",tune_model.cv_results_['split'+str(i)+'_test_score'][tune_model.best_index_])\n",
    "\n",
    "print('-'*5)    \n",
    "\n",
    "print('AFTER Tuning Parameters: ', tune_model.best_params_)\n",
    "print(\"AFTER Tuning Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER Tuning Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print('-'*10)\n",
    "\n",
    "best_log = tune_model.best_estimator_\n",
    "print(best_log)\n",
    "#accuracy on test\n",
    "test_Y_hat = best_log.predict(test_X)\n",
    "accuracy = np.sum((test_Y_hat == test_Y))/200.0*100.0\n",
    "print('test accuracy = ' + str(accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_score: 1.0 test_score: 0.9104166666666667\n",
      "epoch: 1 train_score: 1.0 test_score: 0.9\n",
      "epoch: 2 train_score: 1.0 test_score: 0.9020833333333333\n",
      "epoch: 3 train_score: 1.0 test_score: 0.8989583333333333\n",
      "epoch: 4 train_score: 1.0 test_score: 0.903125\n",
      "----------\n",
      "AFTER Tuning Parameters:  {'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 35, 'random_state': 0}\n",
      "AFTER Tuning Training w/bin score mean: 100.00\n",
      "AFTER Tuning Test w/bin score mean: 90.29\n",
      "----------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=35, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "test accuracy = 90.5 %\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [15,25,30,35],\n",
    "              'criterion': ['gini','entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n",
    "              'max_depth': [2,4,6,None], #max depth tree can grow; default is none\n",
    "              'min_samples_split': [2,5,7,10,12], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n",
    "              #'min_samples_leaf': [1,3,5], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n",
    "              'max_features': [2,3,'auto'], #max features to consider when performing split; default none or all\n",
    "              'random_state': [0] #seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\n",
    "             }\n",
    "\n",
    "\n",
    "tune_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid=param_grid, scoring = 'accuracy', cv = cv_split, return_train_score=True)\n",
    "tune_model.fit(x, y)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"epoch:\",i,\"train_score:\",tune_model.cv_results_['split'+str(i)+'_train_score'][tune_model.best_index_],\n",
    "    \"test_score:\",tune_model.cv_results_['split'+str(i)+'_test_score'][tune_model.best_index_])\n",
    "\n",
    "print('-'*10)    \n",
    "\n",
    "print('AFTER Tuning Parameters: ', tune_model.best_params_)\n",
    "print(\"AFTER Tuning Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER Tuning Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print('-'*10)\n",
    "\n",
    "best_log = tune_model.best_estimator_\n",
    "print(best_log)\n",
    "#accuracy on test\n",
    "test_Y_hat = best_log.predict(test_X)\n",
    "accuracy = np.sum((test_Y_hat == test_Y))/200.0*100.0\n",
    "print('test accuracy = ' + str(accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
